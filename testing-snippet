import os
import re
import json
from collections import defaultdict, deque
from typing import Dict, List, Set, Tuple, Optional

class JavaStubParser:
    def __init__(self, stub_folder_path: str):
        self.stub_folder_path = stub_folder_path
        self.classes = {}  # class_name -> ClassInfo
        self.qualified_classes = {}  # fully_qualified_name -> ClassInfo  
        self.class_name_to_qualified = {}  # simple_name -> [qualified_names]
        self.getter_chains = defaultdict(list)  # class_name -> list of getter chains
        self.primitive_types = {
            'String', 'Integer', 'int', 'Long', 'long', 'Double', 'double', 
            'Float', 'float', 'Boolean', 'boolean', 'BigDecimal', 'BigInteger',
            'Date', 'Calendar', 'XMLGregorianCalendar', 'byte[]', 'Byte',
            'Short', 'short', 'Character', 'char', 'Object', 'Number',
            'LocalDate', 'LocalDateTime', 'LocalTime', 'Instant', 'Duration',
            'UUID', 'URI', 'URL', 'BigInteger', 'AtomicInteger', 'AtomicLong',
            'byte', 'Byte[]', 'char[]', 'String[]'
        }
        
    class ClassInfo:
        def __init__(self, name: str, package: str = ""):
            self.name = name
            self.package = package
            self.qualified_name = f"{package}.{name}" if package else name
            self.fields = {}  # field_name -> field_type
            self.getters = {}  # getter_method -> field_name
            self.imports = set()  # imported classes
            self.is_enum = False
            self.is_list_wrapper = False
            self.list_element_type = None
            
    def parse_java_files(self):
        """Parse all Java files in the stub folder and all subdirectories"""
        print(f"Parsing Java files recursively in: {self.stub_folder_path}")
        
        java_files = []
        for root, dirs, files in os.walk(self.stub_folder_path):
            for file in files:
                if file.endswith('.java'):
                    file_path = os.path.join(root, file)
                    java_files.append(file_path)
        
        print(f"Found {len(java_files)} Java files to parse")
        
        # First pass: collect all classes and their packages
        for file_path in java_files:
            try:
                self._parse_single_file(file_path)
            except Exception as e:
                print(f"Error parsing {file_path}: {e}")
        
        # Build lookup maps for type resolution
        self._build_type_lookup_maps()
                        
        print(f"Parsed {len(self.classes)} classes from {len(java_files)} files")
        print(f"Classes span across {len(set(info.package for info in self.classes.values() if info.package))} packages")
        
    def _parse_single_file(self, file_path: str):
        """Parse a single Java file"""
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read()
            
        # Extract package name
        package_match = re.search(r'package\s+([\w\.]+)\s*;', content)
        package_name = package_match.group(1) if package_match else ""
        
        # Extract imports
        import_matches = re.findall(r'import\s+([\w\.]+)\s*;', content)
        imports = set(import_matches)
        
        # Remove comments and clean up
        content = self._remove_comments(content)
        
        # Extract class definitions
        class_matches = re.finditer(
            r'(?:public\s+)?(?:class|enum|interface)\s+(\w+)(?:\s+extends\s+\w+)?(?:\s+implements\s+[\w,\s]+)?\s*{',
            content, re.MULTILINE
        )
        
        for match in class_matches:
            class_name = match.group(1)
            class_start = match.start()
            
            # Find the class body
            class_body = self._extract_class_body(content, class_start)
            if class_body:
                self._parse_class_content(class_name, class_body, content, package_name, imports)
                
    def _remove_comments(self, content: str) -> str:
        """Remove Java comments from content"""
        # Remove single line comments
        content = re.sub(r'//.*$', '', content, flags=re.MULTILINE)
        # Remove multi-line comments
        content = re.sub(r'/\*.*?\*/', '', content, flags=re.DOTALL)
        return content
        
    def _extract_class_body(self, content: str, start_pos: int) -> Optional[str]:
        """Extract the body of a class using brace matching"""
        brace_count = 0
        class_start = -1
        
        for i in range(start_pos, len(content)):
            if content[i] == '{':
                if class_start == -1:
                    class_start = i + 1
                brace_count += 1
            elif content[i] == '}':
                brace_count -= 1
                if brace_count == 0 and class_start != -1:
                    return content[class_start:i]
        return None
        
    def _parse_class_content(self, class_name: str, class_body: str, full_content: str, package_name: str = "", imports: set = None):
        """Parse the content of a class"""
        class_info = self.ClassInfo(class_name, package_name)
        class_info.imports = imports or set()
        
        # Check if it's an enum
        if 'enum ' + class_name in full_content:
            class_info.is_enum = True
            self.classes[class_name] = class_info
            self.qualified_classes[class_info.qualified_name] = class_info
            return
            
        # Parse fields with multiple patterns
        field_patterns = [
            # Standard field declaration
            r'(?:protected|private|public)?\s+(?:static\s+)?(?:final\s+)?([A-Za-z_][\w<>,\[\]\s]*)\s+(\w+)\s*[;=]',
            # Fields with @XmlElement or other annotations
            r'@\w+[^}]*?(?:protected|private|public)?\s+(?:static\s+)?(?:final\s+)?([A-Za-z_][\w<>,\[\]\s]*)\s+(\w+)\s*[;=]',
        ]
        
        all_field_matches = []
        for pattern in field_patterns:
            matches = re.findall(pattern, class_body, re.MULTILINE | re.DOTALL)
            all_field_matches.extend(matches)
        
        # Remove duplicates while preserving order
        seen_fields = set()
        unique_field_matches = []
        for field_type, field_name in all_field_matches:
            if field_name not in seen_fields:
                seen_fields.add(field_name)
                unique_field_matches.append((field_type, field_name))
        
        for field_type, field_name in unique_field_matches:
            # Clean up the field type
            field_type = self._clean_type(field_type)
            class_info.fields[field_name] = field_type
            
            # Check if this is a List wrapper class
            if field_type.startswith('List<') or field_type.startswith('ArrayList<'):
                class_info.is_list_wrapper = True
                # Extract the element type from List<ElementType>
                element_match = re.search(r'List<([^>]+)>', field_type)
                if element_match:
                    class_info.list_element_type = element_match.group(1).strip()
                    
        # Parse getter methods with more comprehensive patterns
        getter_patterns = [
            # Standard getters
            r'(?:public|protected)\s+([A-Za-z_][\w<>,\[\]\s]*)\s+(get\w+|is\w+)\s*\([^)]*\)\s*{',
            # Getters with annotations
            r'@\w+[^}]*?(?:public|protected)\s+([A-Za-z_][\w<>,\[\]\s]*)\s+(get\w+|is\w+)\s*\([^)]*\)\s*{',
        ]
        
        all_getter_matches = []
        for pattern in getter_patterns:
            matches = re.findall(pattern, class_body, re.MULTILINE | re.DOTALL)
            all_getter_matches.extend(matches)
        
        # Remove duplicates
        seen_getters = set()
        unique_getter_matches = []
        for return_type, getter_method in all_getter_matches:
            if getter_method not in seen_getters:
                seen_getters.add(getter_method)
                unique_getter_matches.append((return_type, getter_method))
        
        for return_type, getter_method in unique_getter_matches:
            return_type = self._clean_type(return_type)
            # Infer field name from getter method
            field_name = self._getter_to_field_name(getter_method)
            
            # Update field type if we found it through getter
            if field_name in class_info.fields:
                class_info.fields[field_name] = return_type
            else:
                class_info.fields[field_name] = return_type
                
            class_info.getters[getter_method] = field_name
            
        self.classes[class_name] = class_info
        self.qualified_classes[class_info.qualified_name] = class_info
        
    def _clean_type(self, type_str: str) -> str:
        """Clean up Java type string"""
        # Remove extra whitespace
        type_str = ' '.join(type_str.split())
        # Handle generic types
        type_str = type_str.replace(' <', '<').replace('< ', '<').replace(' >', '>')
        return type_str.strip()
        
    def _getter_to_field_name(self, getter_method: str) -> str:
        """Convert getter method name to field name"""
        if getter_method.startswith('get'):
            field_name = getter_method[3:]  # Remove 'get'
        elif getter_method.startswith('is'):
            field_name = getter_method[2:]   # Remove 'is'
        else:
            field_name = getter_method
            
        # Convert first letter to lowercase
        if field_name:
            field_name = field_name[0].lower() + field_name[1:]
    def _build_type_lookup_maps(self):
        """Build lookup maps for resolving types across packages"""
        for class_info in self.classes.values():
            simple_name = class_info.name
            if simple_name not in self.class_name_to_qualified:
                self.class_name_to_qualified[simple_name] = []
            self.class_name_to_qualified[simple_name].append(class_info.qualified_name)
    
    def _resolve_type(self, type_name: str, current_class_info: 'ClassInfo' = None) -> str:
        """Resolve a type name to its fully qualified name"""
        # Remove generic parameters for resolution
        base_type = re.sub(r'<.*>', '', type_name).strip()
        
        # If already qualified or primitive, return as is
        if '.' in base_type or base_type in self.primitive_types:
            return type_name
            
        # Try exact match first
        if base_type in self.classes:
            return type_name
            
        # Look for the type in qualified classes
        if base_type in self.class_name_to_qualified:
            candidates = self.class_name_to_qualified[base_type]
            
            # If current class info is available, prefer same package
            if current_class_info and current_class_info.package:
                same_package_candidate = f"{current_class_info.package}.{base_type}"
                if same_package_candidate in candidates:
                    return type_name  # Use simple name but we know it resolves
                    
                # Check imports
                for import_name in current_class_info.imports:
                    if import_name.endswith('.' + base_type) and import_name in candidates:
                        return type_name  # Use simple name but we know it resolves
            
            # If only one candidate, use it
            if len(candidates) == 1:
                return type_name
                
        return type_name  # Return as-is if can't resolve
    
    def _find_class_info(self, type_name: str, current_class_info: 'ClassInfo' = None) -> 'ClassInfo':
        """Find ClassInfo for a given type name"""
        base_type = re.sub(r'<.*>', '', type_name).strip()
        
        # Try simple name first
        if base_type in self.classes:
            return self.classes[base_type]
            
        # Try qualified lookup
        if base_type in self.class_name_to_qualified:
            candidates = self.class_name_to_qualified[base_type]
            
            if current_class_info:
                # Prefer same package
                same_package = f"{current_class_info.package}.{base_type}"
                if same_package in self.qualified_classes:
                    return self.qualified_classes[same_package]
                    
                # Check imports
                for import_name in current_class_info.imports:
                    if import_name.endswith('.' + base_type) and import_name in self.qualified_classes:
                        return self.qualified_classes[import_name]
            
            # Return first candidate if available
            if candidates and candidates[0] in self.qualified_classes:
                return self.qualified_classes[candidates[0]]
                
        return None
        
    def generate_getter_chains(self, root_class_name: str, max_depth: int = 10):
        """Generate all possible getter chains from the root class"""
        print(f"Generating getter chains for root class: {root_class_name}")
        
        if root_class_name not in self.classes:
            print(f"Root class {root_class_name} not found!")
            return []
            
        visited = set()
        all_chains = []
        
        def dfs(current_class: str, chain: List[str], depth: int):
            if depth > max_depth or current_class in visited:
                return
                
            if current_class not in self.classes:
                print(f"DEBUG: Class '{current_class}' not found in parsed classes")
                # Try to find it using the new type resolution
                class_info = self._find_class_info(current_class, self.classes.get(root_class_name))
                if not class_info:
                    return
            else:
                class_info = self.classes[current_class]
                
            visited.add(current_class)
            
            print(f"DEBUG: Processing class '{current_class}' at depth {depth}, getters: {list(class_info.getters.keys())}")
            
            # Add current chain if it's not empty
            if chain:
                all_chains.append(chain.copy())
            
            # Explore each field/getter
            for getter_method, field_name in class_info.getters.items():
                field_type = class_info.fields.get(field_name, '')
                print(f"DEBUG: Getter '{getter_method}' -> field '{field_name}' -> type '{field_type}'")
                
                # Handle List types
                if field_type.startswith('List<') or field_type.startswith('ArrayList<'):
                    element_type = re.search(r'List<([^>]+)>', field_type)
                    if element_type:
                        element_class = element_type.group(1).strip()
                        print(f"DEBUG: Found list element type: '{element_class}'")
                        new_chain = chain + [f"{getter_method}()"]
                        all_chains.append(new_chain.copy())
                        
                        # Add indexed access for list elements
                        indexed_chain = chain + [f"{getter_method}().get(i)"]
                        all_chains.append(indexed_chain.copy())
                        
                        # Continue with the element type
                        if element_class not in self.primitive_types:
                            element_class_info = self._find_class_info(element_class, class_info)
                            if element_class_info:
                                print(f"DEBUG: Continuing DFS with element class '{element_class}'")
                                dfs(element_class_info.name, indexed_chain, depth + 1)
                            else:
                                print(f"DEBUG: Element class '{element_class}' not found")
                        else:
                            print(f"DEBUG: Element class '{element_class}' is primitive")
                
                # Handle regular object types
                elif field_type not in self.primitive_types:
                    target_class_info = self._find_class_info(field_type, class_info)
                    if target_class_info:
                        print(f"DEBUG: Found complex type '{field_type}', continuing DFS")
                        new_chain = chain + [f"{getter_method}()"]
                        dfs(target_class_info.name, new_chain, depth + 1)
                    else:
                        print(f"DEBUG: Type '{field_type}' not found - might be missing from parsed classes")
                
                # Handle primitive types (end of chain)
                elif field_type in self.primitive_types:
                    primitive_chain = chain + [f"{getter_method}()"]
                    all_chains.append(primitive_chain.copy())
                    print(f"DEBUG: Added primitive chain: {primitive_chain}")
                else:
                    print(f"DEBUG: Type '{field_type}' not found - might be missing from parsed classes")
            
            visited.remove(current_class)
        
        # Start DFS from root
        dfs(root_class_name, [], 0)
        
        # Clean up and format chains
        formatted_chains = []
        for chain in all_chains:
            if chain:  # Skip empty chains
                chain_str = "rootObject." + ".".join(chain)
                formatted_chains.append(chain_str)
                
        # Remove duplicates and sort
        formatted_chains = list(set(formatted_chains))
        formatted_chains.sort()
        
        self.getter_chains[root_class_name] = formatted_chains
        return formatted_chains
        
    def export_results(self, output_file: str = "getter_chains_analysis.json"):
        """Export the analysis results to a JSON file"""
        results = {
            "classes": {},
            "getter_chains": dict(self.getter_chains),
            "summary": {
                "total_classes": len(self.classes),
                "total_chains": sum(len(chains) for chains in self.getter_chains.values())
            }
        }
        
        # Export class information
        for class_name, class_info in self.classes.items():
            results["classes"][class_name] = {
                "fields": class_info.fields,
                "getters": class_info.getters,
                "is_enum": class_info.is_enum,
                "is_list_wrapper": class_info.is_list_wrapper,
                "list_element_type": class_info.list_element_type
            }
            
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
            
        print(f"Results exported to: {output_file}")
        
    def print_analysis_summary(self):
        """Print a summary of the analysis"""
        print("\n" + "="*60)
        print("JAVA STUB ANALYSIS SUMMARY")
        print("="*60)
        print(f"Total Classes Parsed: {len(self.classes)}")
        
        enum_count = sum(1 for c in self.classes.values() if c.is_enum)
        list_wrapper_count = sum(1 for c in self.classes.values() if c.is_list_wrapper)
        
        print(f"Enum Classes: {enum_count}")
        print(f"List Wrapper Classes: {list_wrapper_count}")
        print(f"Regular Classes: {len(self.classes) - enum_count - list_wrapper_count}")
        
        # Only show getter chains if they exist
        if self.getter_chains:
            for root_class, chains in self.getter_chains.items():
                chain_count = len(chains) if chains else 0
                print(f"\nGetter Chains for {root_class}: {chain_count} chains found")
            
    def find_root_classes(self) -> List[str]:
        """Identify potential root classes (classes that are not referenced as field types)"""
        referenced_types = set()
        
        for class_info in self.classes.values():
            for field_type in class_info.fields.values():
                # Extract base type from generic types
                base_type = re.sub(r'<.*>', '', field_type).strip()
                referenced_types.add(base_type)
                
        # Root classes are those not referenced as field types
        root_candidates = []
        for class_name in self.classes.keys():
            if class_name not in referenced_types:
                root_candidates.append(class_name)
                
        return root_candidates


def main():
    # Configuration
    STUB_FOLDER_PATH = input("Enter the path to your Java stub folder: ").strip()
    
    if not os.path.exists(STUB_FOLDER_PATH):
        print(f"Error: Path '{STUB_FOLDER_PATH}' does not exist!")
        return
        
    # Initialize parser
    parser = JavaStubParser(STUB_FOLDER_PATH)
    
    # Parse all Java files
    parser.parse_java_files()
    
    # Enhanced Debug: Show comprehensive parsing results
    print(f"\nDETAILED PARSING RESULTS:")
    print(f"Total Java files found: {sum(1 for root, dirs, files in os.walk(parser.stub_folder_path) for file in files if file.endswith('.java'))}")
    print(f"Total classes parsed: {len(parser.classes)}")
    print(f"Packages found: {len(set(info.package for info in parser.classes.values() if info.package))}")
    
    # Show sample classes from different packages
    packages = {}
    for class_info in parser.classes.values():
        pkg = class_info.package or "default"
        if pkg not in packages:
            packages[pkg] = []
        packages[pkg].append(class_info.name)
    
    print(f"\nSample classes by package:")
    for pkg, classes in list(packages.items())[:5]:  # Show first 5 packages
        print(f"  {pkg}: {classes[:3]}")  # Show first 3 classes per package
    
    # Debug: Show some class details
    print(f"\nSample class details:")
    for i, (class_name, class_info) in enumerate(list(parser.classes.items())[:3]):
        print(f"  {class_name}:")
        print(f"    Package: {class_info.package}")
        print(f"    Fields: {list(class_info.fields.keys())[:5]}")  # First 5 fields
        print(f"    Getters: {list(class_info.getters.keys())[:5]}")  # First 5 getters
        print(f"    Field Types: {list(class_info.fields.values())[:5]}")  # First 5 types
    
    # Print summary
    parser.print_analysis_summary()
    
    # Find potential root classes
    root_candidates = parser.find_root_classes()
    print(f"\nPotential Root Classes Found: {len(root_candidates)}")
    for i, root_class in enumerate(root_candidates[:10], 1):  # Show first 10
        print(f"{i}. {root_class}")
    
    if len(root_candidates) > 10:
        print(f"... and {len(root_candidates) - 10} more")
    
    # Get root class from user
    if root_candidates:
        print(f"\nSuggested root class: {root_candidates[0]}")
        root_class_input = input(f"Enter root class name (or press Enter for '{root_candidates[0]}'): ").strip()
        root_class = root_class_input if root_class_input else root_candidates[0]
    else:
        root_class = input("Enter the root class name: ").strip()
    
    print(f"\nUsing root class: {root_class}")
    
    # Debug: Check if root class exists and show its details
    if root_class not in parser.classes:
        print(f"WARNING: Root class '{root_class}' not found in parsed classes!")
        print("Available classes:", list(parser.classes.keys())[:10])
        
        # Try to find similar class names
        similar_classes = [name for name in parser.classes.keys() if root_class.lower() in name.lower()]
        if similar_classes:
            print(f"Similar classes found: {similar_classes}")
        return
    
    # Show root class details
    root_info = parser.classes[root_class]
    print(f"\nROOT CLASS DETAILS:")
    print(f"Name: {root_info.name}")
    print(f"Package: {root_info.package}")
    print(f"Qualified name: {root_info.qualified_name}")
    print(f"Total fields: {len(root_info.fields)}")
    print(f"Total getters: {len(root_info.getters)}")
    print(f"Field types: {list(root_info.fields.values())}")
    print(f"Getter methods: {list(root_info.getters.keys())}")
    
    # Check if field types are resolved
    print(f"\nTYPE RESOLUTION CHECK:")
    for field_name, field_type in root_info.fields.items():
        base_type = re.sub(r'<.*>', '', field_type).strip()
        found_info = parser._find_class_info(base_type, root_info)
        status = "✓ Found" if found_info else "✗ Missing"
        print(f"  {field_name} ({field_type}): {status}")
        if found_info:
            print(f"    -> Resolved to: {found_info.qualified_name} with {len(found_info.getters)} getters")
    
    # Generate getter chains with more debugging
    max_depth = int(input("Enter maximum depth for getter chains (default: 10): ") or "10")
    print(f"\nStarting getter chain generation with max depth: {max_depth}")
    chains = parser.generate_getter_chains(root_class, max_depth)
    
    # Handle case where chains is None or empty
    if not chains:
        print(f"No getter chains found for class '{root_class}'. Please check:")
        print("1. The class name is correct")
        print("2. The class has getter methods")
        print("3. The Java files were parsed correctly")
        return
    
    # Display results
    print(f"\n{'='*60}")
    print(f"GETTER CHAINS FOR {root_class}")
    print(f"{'='*60}")
    print(f"Total chains found: {len(chains)}")
    print("\nFirst 20 getter chains:")
    for i, chain in enumerate(chains[:20], 1):
        print(f"{i:2d}. {chain}")
        
    if len(chains) > 20:
        print(f"\n... and {len(chains) - 20} more chains")
    
    # Export results
    output_file = f"getter_chains_{root_class.lower()}.json"
    parser.export_results(output_file)
    
    # Also create a simple text file with just the chains
    chains_file = f"getter_chains_{root_class.lower()}.txt"
    with open(chains_file, 'w', encoding='utf-8') as f:
        f.write(f"Getter Chains for {root_class}\n")
        f.write(f"Generated on: {parser.stub_folder_path}\n")
        f.write(f"Total chains: {len(chains)}\n\n")
        for i, chain in enumerate(chains, 1):
            f.write(f"{i:4d}. {chain}\n")
    
    print(f"\nGetter chains saved to: {chains_file}")
    print("Analysis complete!")


if __name__ == "__main__":
    main()
