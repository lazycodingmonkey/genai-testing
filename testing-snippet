import os
import re
import json
from collections import defaultdict, deque
from typing import Dict, List, Set, Tuple, Optional

class JavaStubParser:
    def __init__(self, stub_folder_path: str):
        self.stub_folder_path = stub_folder_path
        self.classes = {}  # class_name -> ClassInfo
        self.qualified_classes = {}  # fully_qualified_name -> ClassInfo  
        self.class_name_to_qualified = {}  # simple_name -> [qualified_names]
        self.getter_chains = defaultdict(list)  # class_name -> list of getter chains
        self.primitive_types = {
            'String', 'Integer', 'int', 'Long', 'long', 'Double', 'double', 
            'Float', 'float', 'Boolean', 'boolean', 'BigDecimal', 'BigInteger',
            'Date', 'Calendar', 'XMLGregorianCalendar', 'byte[]', 'Byte',
            'Short', 'short', 'Character', 'char', 'Object', 'Number',
            'LocalDate', 'LocalDateTime', 'LocalTime', 'Instant', 'Duration',
            'UUID', 'URI', 'URL', 'BigInteger', 'AtomicInteger', 'AtomicLong',
            'byte', 'Byte[]', 'char[]', 'String[]'
        }
        
    class ClassInfo:
        def __init__(self, name: str, package: str = ""):
            self.name = name
            self.package = package
            self.qualified_name = f"{package}.{name}" if package else name
            self.fields = {}  # field_name -> field_type
            self.getters = {}  # getter_method -> field_name
            self.imports = set()  # imported classes
            self.is_enum = False
            self.is_list_wrapper = False
            self.list_element_type = None
            
    def parse_java_files(self):
        """Parse all Java files in the stub folder and all subdirectories"""
        print(f"Parsing Java files recursively in: {self.stub_folder_path}")
        
        java_files = []
        for root, dirs, files in os.walk(self.stub_folder_path):
            java_files_in_dir = [os.path.join(root, f) for f in files if f.endswith('.java')]
            java_files.extend(java_files_in_dir)
            
        print(f"Total Java files found: {len(java_files)}")
        
        if not java_files:
            print(f"ERROR: No Java files found in {self.stub_folder_path}")
            return
            
        for file_path in java_files:
            try:
                self._parse_single_file(file_path)
            except Exception as e:
                print(f"ERROR parsing {file_path}: {e}")
        
        self._build_type_lookup_maps()
        print(f"Classes extracted: {len(self.classes)}")
            
    def _parse_single_file(self, file_path: str):
        """Parse a single Java file"""
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read()
            
        # Extract package name
        package_match = re.search(r'package\s+([\w\.]+)\s*;', content)
        package_name = package_match.group(1) if package_match else ""
        
        # Extract imports
        import_matches = re.findall(r'import\s+([\w\.]+)\s*;', content)
        imports = set(import_matches)
        
        # Remove comments and clean up
        content = self._remove_comments(content)
        
        # Extract class definitions - more flexible regex
        class_matches = re.finditer(
            r'public\s+(?:abstract\s+)?(?:final\s+)?(?:class|enum|interface)\s+(\w+)(?:\s+extends\s+\w+)?(?:\s+implements\s+[\w,\s]+)?\s*{',
            content, re.MULTILINE
        )
        
        for match in class_matches:
            class_name = match.group(1)
            class_start = match.start()
            
            # Find the class body
            class_body = self._extract_class_body(content, class_start)
            if class_body:
                self._parse_class_content(class_name, class_body, content, package_name, imports)
                
    def _remove_comments(self, content: str) -> str:
        """Remove Java comments from content"""
        content = re.sub(r'//.*$', '', content, flags=re.MULTILINE)
        content = re.sub(r'/\*.*?\*/', '', content, flags=re.DOTALL)
        return content
        
    def _extract_class_body(self, content: str, start_pos: int) -> Optional[str]:
        """Extract the body of a class using brace matching"""
        brace_count = 0
        class_start = -1
        
        for i in range(start_pos, len(content)):
            if content[i] == '{':
                if class_start == -1:
                    class_start = i + 1
                brace_count += 1
            elif content[i] == '}':
                brace_count -= 1
                if brace_count == 0 and class_start != -1:
                    return content[class_start:i]
        return None
        
    def _parse_class_content(self, class_name: str, class_body: str, full_content: str, package_name: str = "", imports: set = None):
        """Parse the content of a class"""
        class_info = self.ClassInfo(class_name, package_name)
        class_info.imports = imports or set()
        
        if 'enum ' + class_name in full_content:
            class_info.is_enum = True
            self.classes[class_name] = class_info
            self.qualified_classes[class_info.qualified_name] = class_info
            return
            
        # Method 1: Parse from getter methods (most reliable for WSDL stubs)
        getter_pattern = r'public\s+([A-Za-z_][\w<>,\[\]\.\s]*?)\s+(get\w+|is\w+)\s*\(\s*\)\s*\{[^}]*return\s+[^;]*;'
        getter_matches = re.findall(getter_pattern, class_body, re.MULTILINE | re.DOTALL)
        
        for return_type, getter_method in getter_matches:
            clean_type = self._clean_type(return_type)
            field_name = self._getter_to_field_name(getter_method)
            class_info.fields[field_name] = clean_type
            class_info.getters[getter_method] = field_name
            
        # Method 2: Fallback to field declarations if no getters found
        if not class_info.fields:
            field_pattern = r'(?:protected|public|private)\s+([A-Za-z_][\w<>,\[\]\.\s]+?)\s+(\w+)\s*;'
            field_matches = re.findall(field_pattern, class_body, re.MULTILINE)
            for field_type, field_name in field_matches:
                clean_type = self._clean_type(field_type)
                class_info.fields[field_name] = clean_type

        # Check for list wrapper pattern
        if len(class_info.fields) == 1:
            field_name, field_type = list(class_info.fields.items())[0]
            if "List<" in field_type:
                class_info.is_list_wrapper = True
                match = re.search(r'List<(.+?)>', field_type)
                if match:
                    class_info.list_element_type = self._clean_type(match.group(1))
        
        self.classes[class_name] = class_info
        self.qualified_classes[class_info.qualified_name] = class_info
            
    def _clean_type(self, type_str: str) -> str:
        """Clean up Java type string - IMPROVED VERSION"""
        if not type_str:
            return type_str
        
        # Remove annotations
        type_str = re.sub(r'@\w+(\([^)]*\))?\s*', '', type_str)
        # Handle JAXBElement wrapper
        jaxb_match = re.search(r'JAXBElement<(.*?)>', type_str)
        if jaxb_match:
            type_str = jaxb_match.group(1).strip()
        # Handle List generic type
        list_match = re.search(r'(List|ArrayList)<(.+?)>', type_str)
        if list_match:
            element_type = self._clean_type(list_match.group(2))
            return f"List<{element_type}>"
        # Handle namespace prefixes (e.g., "ns1:CustomerType")
        if ':' in type_str:
            type_str = type_str.split(':')[-1]
            
        type_str = re.sub(r'\s+', '', type_str).strip()
        
        return type_str
        
    def _getter_to_field_name(self, getter_method: str) -> str:
        """Convert getter method name to field name"""
        if getter_method.startswith('get'):
            field_name = getter_method[3:]
        elif getter_method.startswith('is'):
            field_name = getter_method[2:]
        else:
            field_name = getter_method
            
        if field_name:
            field_name = field_name[0].lower() + field_name[1:]
            
        # Remove any leading `_` that might be present
        if field_name.startswith('_'):
            field_name = field_name[1:]
            
        return field_name
            
    def _build_type_lookup_maps(self):
        """Build lookup maps for resolving types across packages"""
        for class_info in self.classes.values():
            simple_name = class_info.name
            if simple_name not in self.class_name_to_qualified:
                self.class_name_to_qualified[simple_name] = []
            self.class_name_to_qualified[simple_name].append(class_info.qualified_name)
    
    def _find_class_info(self, type_name: str, current_class_info: 'ClassInfo' = None) -> Optional['ClassInfo']:
        """Find ClassInfo for a given type name using a more robust search strategy"""
        base_type = re.sub(r'<.*>', '', type_name).strip()
        
        # 1. Direct match (simple name)
        if base_type in self.classes:
            return self.classes[base_type]
            
        # 2. Check imports
        if current_class_info:
            for import_name in current_class_info.imports:
                if import_name.endswith('.' + base_type) and import_name in self.qualified_classes:
                    return self.qualified_classes[import_name]
        
        # 3. Check same package
        if current_class_info and current_class_info.package:
            qualified_name = f"{current_class_info.package}.{base_type}"
            if qualified_name in self.qualified_classes:
                return self.qualified_classes[qualified_name]
                
        # 4. Check all qualified candidates (multiple classes with same simple name)
        if base_type in self.class_name_to_qualified:
            candidates = self.class_name_to_qualified[base_type]
            if len(candidates) == 1:
                return self.qualified_classes.get(candidates[0])
            # Ambiguous case, requires more context, which we don't have. Return first candidate.
            if candidates:
                 return self.qualified_classes.get(candidates[0])

        return None
        
    def generate_getter_chains(self, root_class_name: str, max_depth: int = 10):
        """Generate all possible getter chains from the root class using BFS"""
        if root_class_name not in self.classes:
            print(f"Root class '{root_class_name}' not found!")
            return []
            
        root_info = self.classes[root_class_name]
        all_chains = set()
        queue = deque([(root_info, "", 0)])  # (current_class_info, current_chain_prefix, depth)
        
        print(f"Starting BFS for getter chains from '{root_class_name}'...")
        
        while queue:
            current_info, current_chain, depth = queue.popleft()
            
            if depth >= max_depth:
                continue
                
            for getter_method, field_name in current_info.getters.items():
                field_type = current_info.fields.get(field_name)
                
                if not field_type:
                    continue
                    
                new_chain_part = f".{getter_method}()" if current_chain else f"{getter_method}()"
                new_chain = current_chain + new_chain_part

                all_chains.add(new_chain)

                # Handle List and ArrayList types
                if field_type.startswith('List<') or field_type.startswith('ArrayList<'):
                    match = re.search(r'List<(.+?)>', field_type)
                    if match:
                        element_type = match.group(1)
                        element_info = self._find_class_info(element_type, current_info)
                        if element_info:
                            # Add a chain with indexed access
                            indexed_chain = new_chain + ".get(i)"
                            all_chains.add(indexed_chain)
                            # Add the nested object to the queue for further exploration
                            queue.append((element_info, indexed_chain, depth + 1))
                        else:
                            # Primitive or un-parsed list element type
                            continue

                # Handle regular object types
                else:
                    target_class_info = self._find_class_info(field_type, current_info)
                    if target_class_info:
                        queue.append((target_class_info, new_chain, depth + 1))

        formatted_chains = [f"rootObject.{chain}" for chain in all_chains]
        
        self.getter_chains[root_class_name] = sorted(list(set(formatted_chains)))
        return self.getter_chains[root_class_name]

    def export_results(self, output_file: str = "getter_chains_analysis.json"):
        """Export the analysis results to a JSON file"""
        results = {
            "classes": {},
            "getter_chains": dict(self.getter_chains),
            "summary": {
                "total_classes": len(self.classes),
                "total_chains": sum(len(chains) for chains in self.getter_chains.values())
            }
        }
        
        for class_name, class_info in self.classes.items():
            results["classes"][class_name] = {
                "fields": class_info.fields,
                "getters": class_info.getters,
                "is_enum": class_info.is_enum,
                "is_list_wrapper": class_info.is_list_wrapper,
                "list_element_type": class_info.list_element_type
            }
            
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f,
