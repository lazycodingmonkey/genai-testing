import os
import re
import json
from collections import defaultdict, deque
from typing import Dict, List, Set, Tuple, Optional

class JavaStubParser:
    def __init__(self, stub_folder_path: str):
        self.stub_folder_path = stub_folder_path
        self.classes = {}  # class_name -> ClassInfo
        self.getter_chains = defaultdict(list)  # class_name -> list of getter chains
        self.primitive_types = {
            'String', 'Integer', 'int', 'Long', 'long', 'Double', 'double', 
            'Float', 'float', 'Boolean', 'boolean', 'BigDecimal', 'BigInteger',
            'Date', 'Calendar', 'XMLGregorianCalendar', 'byte[]', 'Byte'
        }
        
    class ClassInfo:
        def __init__(self, name: str):
            self.name = name
            self.fields = {}  # field_name -> field_type
            self.getters = {}  # getter_method -> field_name
            self.is_enum = False
            self.is_list_wrapper = False
            self.list_element_type = None
            
    def parse_java_files(self):
        """Parse all Java files in the stub folder"""
        print(f"Parsing Java files in: {self.stub_folder_path}")
        
        for root, dirs, files in os.walk(self.stub_folder_path):
            for file in files:
                if file.endswith('.java'):
                    file_path = os.path.join(root, file)
                    try:
                        self._parse_single_file(file_path)
                    except Exception as e:
                        print(f"Error parsing {file_path}: {e}")
                        
        print(f"Parsed {len(self.classes)} classes")
        
    def _parse_single_file(self, file_path: str):
        """Parse a single Java file"""
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read()
            
        # Remove comments and clean up
        content = self._remove_comments(content)
        
        # Extract class definitions
        class_matches = re.finditer(
            r'(?:public\s+)?(?:class|enum|interface)\s+(\w+)(?:\s+extends\s+\w+)?(?:\s+implements\s+[\w,\s]+)?\s*{',
            content, re.MULTILINE
        )
        
        for match in class_matches:
            class_name = match.group(1)
            class_start = match.start()
            
            # Find the class body
            class_body = self._extract_class_body(content, class_start)
            if class_body:
                self._parse_class_content(class_name, class_body, content)
                
    def _remove_comments(self, content: str) -> str:
        """Remove Java comments from content"""
        # Remove single line comments
        content = re.sub(r'//.*$', '', content, flags=re.MULTILINE)
        # Remove multi-line comments
        content = re.sub(r'/\*.*?\*/', '', content, flags=re.DOTALL)
        return content
        
    def _extract_class_body(self, content: str, start_pos: int) -> Optional[str]:
        """Extract the body of a class using brace matching"""
        brace_count = 0
        class_start = -1
        
        for i in range(start_pos, len(content)):
            if content[i] == '{':
                if class_start == -1:
                    class_start = i + 1
                brace_count += 1
            elif content[i] == '}':
                brace_count -= 1
                if brace_count == 0 and class_start != -1:
                    return content[class_start:i]
        return None
        
    def _parse_class_content(self, class_name: str, class_body: str, full_content: str):
        """Parse the content of a class"""
        class_info = self.ClassInfo(class_name)
        
        # Check if it's an enum
        if 'enum ' + class_name in full_content:
            class_info.is_enum = True
            self.classes[class_name] = class_info
            return
            
        # Parse fields
        field_pattern = r'(?:protected|private|public)?\s+(?:static\s+)?(?:final\s+)?([A-Za-z_][\w<>,\[\]\s]*)\s+(\w+)\s*[;=]'
        field_matches = re.findall(field_pattern, class_body)
        
        for field_type, field_name in field_matches:
            # Clean up the field type
            field_type = self._clean_type(field_type)
            class_info.fields[field_name] = field_type
            
            # Check if this is a List wrapper class
            if field_type.startswith('List<') or field_type.startswith('ArrayList<'):
                class_info.is_list_wrapper = True
                # Extract the element type from List<ElementType>
                element_match = re.search(r'List<([^>]+)>', field_type)
                if element_match:
                    class_info.list_element_type = element_match.group(1).strip()
                    
        # Parse getter methods
        getter_pattern = r'(?:public|protected)\s+([A-Za-z_][\w<>,\[\]\s]*)\s+(get\w+)\s*\([^)]*\)\s*{'
        getter_matches = re.findall(getter_pattern, class_body)
        
        for return_type, getter_method in getter_matches:
            return_type = self._clean_type(return_type)
            # Infer field name from getter method
            field_name = self._getter_to_field_name(getter_method)
            
            # Update field type if we found it through getter
            if field_name in class_info.fields:
                class_info.fields[field_name] = return_type
            else:
                class_info.fields[field_name] = return_type
                
            class_info.getters[getter_method] = field_name
            
        self.classes[class_name] = class_info
        
    def _clean_type(self, type_str: str) -> str:
        """Clean up Java type string"""
        # Remove extra whitespace
        type_str = ' '.join(type_str.split())
        # Handle generic types
        type_str = type_str.replace(' <', '<').replace('< ', '<').replace(' >', '>')
        return type_str.strip()
        
    def _getter_to_field_name(self, getter_method: str) -> str:
        """Convert getter method name to field name"""
        if getter_method.startswith('get'):
            field_name = getter_method[3:]  # Remove 'get'
        elif getter_method.startswith('is'):
            field_name = getter_method[2:]   # Remove 'is'
        else:
            field_name = getter_method
            
        # Convert first letter to lowercase
        if field_name:
            field_name = field_name[0].lower() + field_name[1:]
        return field_name
        
    def generate_getter_chains(self, root_class_name: str, max_depth: int = 10):
        """Generate all possible getter chains from the root class"""
        print(f"Generating getter chains for root class: {root_class_name}")
        
        if root_class_name not in self.classes:
            print(f"Root class {root_class_name} not found!")
            return
            
        visited = set()
        all_chains = []
        
        def dfs(current_class: str, chain: List[str], depth: int):
            if depth > max_depth or current_class in visited:
                return
                
            if current_class not in self.classes:
                return
                
            visited.add(current_class)
            class_info = self.classes[current_class]
            
            # Add current chain if it's not empty
            if chain:
                all_chains.append(chain.copy())
            
            # Explore each field/getter
            for getter_method, field_name in class_info.getters.items():
                field_type = class_info.fields.get(field_name, '')
                
                # Handle List types
                if field_type.startswith('List<') or field_type.startswith('ArrayList<'):
                    element_type = re.search(r'List<([^>]+)>', field_type)
                    if element_type:
                        element_class = element_type.group(1).strip()
                        new_chain = chain + [f"{getter_method}()"]
                        all_chains.append(new_chain.copy())
                        
                        # Add indexed access for list elements
                        indexed_chain = chain + [f"{getter_method}().get(i)"]
                        all_chains.append(indexed_chain.copy())
                        
                        # Continue with the element type
                        if element_class not in self.primitive_types and element_class in self.classes:
                            dfs(element_class, indexed_chain, depth + 1)
                
                # Handle regular object types
                elif field_type not in self.primitive_types and field_type in self.classes:
                    new_chain = chain + [f"{getter_method}()"]
                    dfs(field_type, new_chain, depth + 1)
                
                # Handle primitive types (end of chain)
                elif field_type in self.primitive_types:
                    primitive_chain = chain + [f"{getter_method}()"]
                    all_chains.append(primitive_chain.copy())
            
            visited.remove(current_class)
        
        # Start DFS from root
        dfs(root_class_name, [], 0)
        
        # Clean up and format chains
        formatted_chains = []
        for chain in all_chains:
            if chain:  # Skip empty chains
                chain_str = "rootObject." + ".".join(chain)
                formatted_chains.append(chain_str)
                
        # Remove duplicates and sort
        formatted_chains = list(set(formatted_chains))
        formatted_chains.sort()
        
        self.getter_chains[root_class_name] = formatted_chains
        return formatted_chains
        
    def export_results(self, output_file: str = "getter_chains_analysis.json"):
        """Export the analysis results to a JSON file"""
        results = {
            "classes": {},
            "getter_chains": dict(self.getter_chains),
            "summary": {
                "total_classes": len(self.classes),
                "total_chains": sum(len(chains) for chains in self.getter_chains.values())
            }
        }
        
        # Export class information
        for class_name, class_info in self.classes.items():
            results["classes"][class_name] = {
                "fields": class_info.fields,
                "getters": class_info.getters,
                "is_enum": class_info.is_enum,
                "is_list_wrapper": class_info.is_list_wrapper,
                "list_element_type": class_info.list_element_type
            }
            
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
            
        print(f"Results exported to: {output_file}")
        
    def print_analysis_summary(self):
        """Print a summary of the analysis"""
        print("\n" + "="*60)
        print("JAVA STUB ANALYSIS SUMMARY")
        print("="*60)
        print(f"Total Classes Parsed: {len(self.classes)}")
        
        enum_count = sum(1 for c in self.classes.values() if c.is_enum)
        list_wrapper_count = sum(1 for c in self.classes.values() if c.is_list_wrapper)
        
        print(f"Enum Classes: {enum_count}")
        print(f"List Wrapper Classes: {list_wrapper_count}")
        print(f"Regular Classes: {len(self.classes) - enum_count - list_wrapper_count}")
        
        for root_class, chains in self.getter_chains.items():
            print(f"\nGetter Chains for {root_class}: {len(chains)} chains found")
            
    def find_root_classes(self) -> List[str]:
        """Identify potential root classes (classes that are not referenced as field types)"""
        referenced_types = set()
        
        for class_info in self.classes.values():
            for field_type in class_info.fields.values():
                # Extract base type from generic types
                base_type = re.sub(r'<.*>', '', field_type).strip()
                referenced_types.add(base_type)
                
        # Root classes are those not referenced as field types
        root_candidates = []
        for class_name in self.classes.keys():
            if class_name not in referenced_types:
                root_candidates.append(class_name)
                
        return root_candidates


def main():
    # Configuration
    STUB_FOLDER_PATH = input("Enter the path to your Java stub folder: ").strip()
    
    if not os.path.exists(STUB_FOLDER_PATH):
        print(f"Error: Path '{STUB_FOLDER_PATH}' does not exist!")
        return
        
    # Initialize parser
    parser = JavaStubParser(STUB_FOLDER_PATH)
    
    # Parse all Java files
    parser.parse_java_files()
    
    # Print summary
    parser.print_analysis_summary()
    
    # Find potential root classes
    root_candidates = parser.find_root_classes()
    print(f"\nPotential Root Classes Found: {len(root_candidates)}")
    for i, root_class in enumerate(root_candidates[:10], 1):  # Show first 10
        print(f"{i}. {root_class}")
    
    if len(root_candidates) > 10:
        print(f"... and {len(root_candidates) - 10} more")
    
    # Get root class from user
    if root_candidates:
        print(f"\nSuggested root class: {root_candidates[0]}")
        root_class_input = input(f"Enter root class name (or press Enter for '{root_candidates[0]}'): ").strip()
        root_class = root_class_input if root_class_input else root_candidates[0]
    else:
        root_class = input("Enter the root class name: ").strip()
    
    # Generate getter chains
    max_depth = int(input("Enter maximum depth for getter chains (default: 8): ") or "8")
    chains = parser.generate_getter_chains(root_class, max_depth)
    
    # Display results
    print(f"\n{'='*60}")
    print(f"GETTER CHAINS FOR {root_class}")
    print(f"{'='*60}")
    print(f"Total chains found: {len(chains)}")
    print("\nFirst 20 getter chains:")
    for i, chain in enumerate(chains[:20], 1):
        print(f"{i:2d}. {chain}")
        
    if len(chains) > 20:
        print(f"\n... and {len(chains) - 20} more chains")
    
    # Export results
    output_file = f"getter_chains_{root_class.lower()}.json"
    parser.export_results(output_file)
    
    # Also create a simple text file with just the chains
    chains_file = f"getter_chains_{root_class.lower()}.txt"
    with open(chains_file, 'w', encoding='utf-8') as f:
        f.write(f"Getter Chains for {root_class}\n")
        f.write(f"Generated on: {parser.stub_folder_path}\n")
        f.write(f"Total chains: {len(chains)}\n\n")
        for i, chain in enumerate(chains, 1):
            f.write(f"{i:4d}. {chain}\n")
    
    print(f"\nGetter chains saved to: {chains_file}")
    print("Analysis complete!")


if __name__ == "__main__":
    main()
